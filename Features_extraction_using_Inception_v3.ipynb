{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction using Inception v3\n",
    "\n",
    "Here we are going to extract features from CIFAR10 dataset images in order to build effective classifier.\n",
    "For this purpose, we use Inception v3 pretrained CNN network and extract features (called CNN codes).\n",
    "\n",
    "**Warning.** The process of extraction can be time consuming.\n",
    "It is recommended to use at least GPU. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained network\n",
    "We use **Inception_v3** network from ***Tensorflow*** model examples which is CNN network trained on the [ILSVRC-2012-CLS](http://www.image-net.org/challenges/LSVRC/2012/) image classification dataset.\n",
    "The model of this CNN is given on the figure below.\n",
    "<center><img src=\"img/Inception_v3_model_graph.png\" width=90% alt=\"Inception v3 model graph\"></center>\n",
    "\n",
    "Following the file [<tt>classify_image.py</tt>](https://github.com/tensorflow/models/blob/master/tutorials/image/imagenet/classify_image.py) from TensorFlow repository \n",
    "one can use the <tt>maybe_download_and_extract()</tt> procedure to download and extract the files, and later <tt>create_graph()</tt> to create an instance of the Tensorflow model of *Inception v3*; see the code below.\n",
    "\n",
    "The first procedure downloads the file\n",
    "> http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz\n",
    "\n",
    "and extracts it giving the most important file, which is <tt>classify_image_graph_def.pb</tt>\n",
    "```python\n",
    "from classify_image import *  # please download classify_image.py first\n",
    "FLAGS.model_dir = './' # path to save the file inception-2015-12-05.tgz\n",
    "maybe_download_and_extract()\n",
    "create_graph()\n",
    "```\n",
    "\n",
    "Having the file <tt>classify_image_graph_def.pb</tt> (assuming in current directory), \n",
    "one can restore it in Tensorflow session using the code\n",
    "```python\n",
    "graph_def = tf.GraphDef()\n",
    "with open('./classify_image_graph_def.pb', \"rb\") as f: # assuming the file is in current directory\n",
    "    graph_def.ParseFromString(f.read())\n",
    "tf.import_graph_def(graph_def, name='')\n",
    "```\n",
    "\n",
    "More models of CNNs, trained on the [ILSVRC-2012-CLS](http://www.image-net.org/challenges/LSVRC/2012/) can be found [here](https://github.com/tensorflow/models/tree/master/slim#pre-trained-models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import myutils\n",
    "import sys\n",
    "import os\n",
    "\n",
    "data_training, data_testing = myutils.load_CIFAR_dataset(shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # One can download classify_image.py from \n",
    "# # https://github.com/tensorflow/models/blob/master/tutorials/image/imagenet/classify_image.py\n",
    "# # Next, it is enough to run this code\n",
    "#\n",
    "# from classify_image import *\n",
    "# FLAGS.model_dir = 'model/'       # path to save the file inception-2015-12-05.tgz\n",
    "# maybe_download_and_extract()\n",
    "# create_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Please download the file with the Inception model\n",
    "# http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz\n",
    "# Extract the model to the file 'model/classify_image_graph_def.pb'\n",
    "#\n",
    "graph_def = tf.GraphDef()\n",
    "with open('model/classify_image_graph_def.pb', \"rb\") as f:\n",
    "    graph_def.ParseFromString(f.read())\n",
    "tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of samples to extract from \n",
    "\n",
    "nsamples_training = 50000    # at most 50000\n",
    "nsamples_testing  = 10000    # at most 10000\n",
    "\n",
    "# nsamples_training = len(data_training)\n",
    "# nsamples_testing  = len(data_testing)\n",
    "\n",
    "nsamples = nsamples_training + nsamples_testing\n",
    "\n",
    "X_data = [ data_training[i][0] for i in range(nsamples_training) ] + \\\n",
    "         [ data_testing[i][0]  for i in range(nsamples_testing)  ]\n",
    "\n",
    "y_training = np.array( [ data_training[i][1] for i in range(nsamples_training) ] )\n",
    "y_testing  = np.array( [ data_testing[i][1]  for i in range(nsamples_testing)  ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation?\n",
    "Lets try to extract features without *data augmentation*.\n",
    "We will do this later, after we see the classification score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running tensorflow session in order to extract features\n",
    "def _progress(count, start, time):\n",
    "    percent = 100.0*(count+1)/nsamples;\n",
    "    sys.stdout.write('\\r>> Extracting features %4d/%d  %6.2f%%   \\\n",
    "                      ETA %8.1f seconds' % (count, nsamples, percent, (time-start)*(100.0-percent)/percent) )\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsamples =  60000\n",
      ">> Extracting features 59999/60000  100.00%                         ETA      0.0 seconds\n",
      "Elapsed time 2047.5 seconds\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')\n",
    "    representation_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "    predictions = np.zeros((nsamples, 1008), dtype='float32')\n",
    "    representations = np.zeros((nsamples, 2048), dtype='float32')\n",
    "\n",
    "    print('nsamples = ', nsamples)\n",
    "    start = time.time()\n",
    "    for i in range(nsamples):\n",
    "        [reps, preds] = sess.run([representation_tensor, softmax_tensor], {'DecodeJpeg:0': X_data[i]})      \n",
    "        predictions[i] = np.squeeze(preds)\n",
    "        representations[i] = np.squeeze(reps)\n",
    "        if i+1==nsamples or not (i%10): _progress(i, start, time.time())\n",
    "    print('\\nElapsed time %.1f seconds' % (time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1008)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So after **2047.5 seconds** we obtained 60000 prediction vectors (each has size of 1008) given by Inception.\n",
    "This can be a little bit confusing at that moment, since Inception was trained on [ILSVRC-2012-CLS](http://www.image-net.org/challenges/LSVRC/2012/) dataset which has 1000 (not 1008) classes of images.\n",
    "\n",
    "There must some explanation for this, but actually we are not interested in the last layer of Inception v3, which is ***softmax***. We do not want the predictions for CIFAR10 dataset given by the network trained for the ILSVRC.\n",
    "\n",
    "Let's take pre-last layer (called ***pool:3***) having features, which can be interesting for us for further *training* or *classification*. We will see the results later (see the notebook [Classification_using_CNN_codes](Classification_using_CNN_codes.ipynb) or [Classification_using_CNN_codes-tensorflow](Classification_using_CNN_codes-tensorflow.ipynb)). This is called **transfer learning** :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 2048)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 60000 feature vectors called **CNN codes**. Each code has 2048 (undoubtedly very interesting) features. Let us remind that original data has images with 3072 features (which are rather useless for classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0004293   0.00397255  0.00011032]\n",
      "[ 0.2105343   0.15321289  0.39882681]\n"
     ]
    }
   ],
   "source": [
    "print( predictions[0,:3] )\n",
    "print( representations[0,:3] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following result should look like\n",
    "<pre>[ 0.0004293   0.00397256  0.00011032]\n",
    "[ 0.21053354  0.15321334  0.39882639]  (using Intel CPU)\n",
    "</pre>\n",
    "or\n",
    "<pre>[ 0.0004293   0.00397257  0.00011032]\n",
    "[ 0.21053371  0.15321358  0.3988266 ]  (using AMD FX(tm)-6300)\n",
    "</pre>\n",
    "or\n",
    "<pre>[ 0.0004293   0.00397255  0.00011032]\n",
    "[ 0.2105343   0.15321289  0.39882681]  (using nVIDIA GPU 1050 X Ti)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finally we can save our work to the file\n",
    "\n",
    "np.savez_compressed(\"features/CIFAR10_Inception_v3_features.npz\",      \\\n",
    "                    features_training=representations[:nsamples_training],  \\\n",
    "                    features_testing=representations[-nsamples_testing:],   \\\n",
    "                    labels_training=y_training,                             \\\n",
    "                    labels_testing=y_testing )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
